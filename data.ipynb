{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, Dense, Input\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.applications import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "data_train = pd.read_csv('./eyes-dataset/Training_Set/Training_Set/RFMiD_Training_Labels.csv')\n",
    "data_test = pd.read_csv('./eyes-dataset/Test_Set/Test_Set/RFMiD_Testing_Labels.csv')\n",
    "data_evaluation = pd.read_csv('./eyes-dataset/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv')\n",
    "\n",
    "# Définir le chemin du dossier contenant les images\n",
    "image_folder_train = './eyes-dataset/Training_Set/Training_Set/Training/'  # Mettez le chemin approprié\n",
    "image_folder_eval = './eyes-dataset/Evaluation_Set/Evaluation_Set/Validation/'  #\n",
    "image_folder_test= './eyes-dataset/Test_Set/Test_Set/Test/'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajout de la colonne image path a chaque datset \n",
    "\n",
    "data_train['path'] = [f'./eyes-dataset/Training_Set/Training_Set/Training/{id}' for id in data_train['ID']]\n",
    "data_test['path'] = [f'./eyes-dataset//Test_Set/Test_Set/Test/{id}' for id in data_test['ID']]\n",
    "data_evaluation['path'] = [f'./eyes-dataset/Evaluation_Set/Evaluation_Set/Validation/{id}' for id in data_evaluation['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Après l'ajout du path dans une olonne on peut donc drop l'id il ne sert plus à rien \n",
    "\n",
    "data_train.drop(columns=['ID'], inplace=True)\n",
    "data_test.drop(columns=['ID'], inplace=True)\n",
    "data_evaluation.drop(columns=['ID'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude = ['path'] \n",
    "\n",
    "# Suppression des colonnes non pertinentes\n",
    "data_for_labels = data_train.drop(columns=cols_to_exclude)\n",
    "\n",
    "# Obtention de la liste des maladies (colonnes restantes) pour l'entraînement, la validation, et les ensembles de tests\n",
    "y_train = y_val = y_test = list(data_for_labels.columns)\n",
    "\n",
    "# Détermination du nombre de maladies uniques\n",
    "unique_diseases = len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Disease_Risk', 'DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'AH', 'ODP', 'ODE', 'AION', 'RS', 'CRS', 'EDN', 'RPEC']\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease_Risk</th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>LS</th>\n",
       "      <th>MS</th>\n",
       "      <th>...</th>\n",
       "      <th>CRVO</th>\n",
       "      <th>AH</th>\n",
       "      <th>ODP</th>\n",
       "      <th>ODE</th>\n",
       "      <th>AION</th>\n",
       "      <th>RS</th>\n",
       "      <th>CRS</th>\n",
       "      <th>EDN</th>\n",
       "      <th>RPEC</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./eyes-dataset/Evaluation_Set/Evaluation_Set/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./eyes-dataset/Evaluation_Set/Evaluation_Set/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./eyes-dataset/Evaluation_Set/Evaluation_Set/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./eyes-dataset/Evaluation_Set/Evaluation_Set/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./eyes-dataset/Evaluation_Set/Evaluation_Set/V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Disease_Risk  DR  ARMD  MH  DN  MYA  BRVO  TSLN  LS  MS  ...  CRVO  AH  \\\n",
       "0             1   1     0   0   0    0     0     1   0   0  ...     0   0   \n",
       "1             1   0     0   0   0    0     0     0   1   0  ...     0   0   \n",
       "2             1   0     0   0   0    0     0     0   1   0  ...     0   0   \n",
       "3             1   0     0   0   0    0     0     0   1   0  ...     0   0   \n",
       "4             1   0     0   0   0    0     0     0   1   0  ...     0   0   \n",
       "\n",
       "   ODP  ODE  AION  RS  CRS  EDN  RPEC  \\\n",
       "0    0    0     0   0    0    0     0   \n",
       "1    0    0     0   0    0    0     0   \n",
       "2    0    0     0   0    0    0     0   \n",
       "3    0    0     0   0    0    0     0   \n",
       "4    0    0     0   0    0    0     0   \n",
       "\n",
       "                                            img_path  \n",
       "0  ./eyes-dataset/Evaluation_Set/Evaluation_Set/V...  \n",
       "1  ./eyes-dataset/Evaluation_Set/Evaluation_Set/V...  \n",
       "2  ./eyes-dataset/Evaluation_Set/Evaluation_Set/V...  \n",
       "3  ./eyes-dataset/Evaluation_Set/Evaluation_Set/V...  \n",
       "4  ./eyes-dataset/Evaluation_Set/Evaluation_Set/V...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 validated image filenames.\n",
      "Found 640 validated image filenames.\n",
      "Found 640 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Création d'une instance de ImageDataGenerator (vous pouvez éventuellement normaliser vos données ici)\n",
    "datagen = ImageDataGenerator(rescale=1./255.)  # normalisation des pixels\n",
    "\n",
    "# Supposons que vous avez des dataframes distincts pour l'entraînement, le test et la validation :\n",
    "# data_train, data_val, data_test et que 'img_path' est la colonne avec le chemin des images.\n",
    "\n",
    "# Chargement des données d'entraînement\n",
    "train_data = datagen.flow_from_dataframe(\n",
    "    dataframe=data_train,\n",
    "    directory=None,  \n",
    "    x_col='path',  \n",
    "    y_col=y_train,  \n",
    "    target_size=(356, 536),  \n",
    "    color_mode='rgb',  \n",
    "    class_mode='raw',  \n",
    "    batch_size=32,  \n",
    "    shuffle=True  \n",
    ")\n",
    "\n",
    "# Chargement des données de validation\n",
    "val_data = datagen.flow_from_dataframe(\n",
    "    dataframe=data_evaluation,  \n",
    "    directory=None,\n",
    "    x_col='img_path',\n",
    "    y_col=y_val,\n",
    "    target_size=(356, 536),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,  \n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "# Chargement des données de test\n",
    "test_data = datagen.flow_from_dataframe(\n",
    "    dataframe=data_test,  \n",
    "    directory=None,\n",
    "    x_col='img_path',\n",
    "    y_col=y_test,\n",
    "    target_size=(356, 536),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,  \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "def augment_image(image):\n",
    "    \n",
    "    image = preprocessing.RandomFlip(\"horizontal\")(image)\n",
    "    \n",
    "    image = preprocessing.RandomFlip(\"vertical\")(image)\n",
    " \n",
    "    return image\n",
    "\n",
    "# Création d'un modèle séquentiel pour la couche d'augmentation de données\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.Lambda(augment_image)  \n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = ResNet50(weights='imagenet', input_shape=(356,536,3), include_top=False)\n",
    "pre_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 12, 17, 1280)      2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21)                1365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2431573 (9.28 MB)\n",
      "Trainable params: 173589 (678.08 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (356, 536, 3)  \n",
    "\n",
    "base_model = MobileNetV2(input_shape=input_shape,\n",
    "                         include_top=False,  \n",
    "                         weights='imagenet')  \n",
    "\n",
    "base_model.trainable = False  \n",
    "\n",
    "# Create a new sequential model and add the layers, including the base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(unique_diseases, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "recall = tf.keras.metrics.Recall(name=\"recall\", thresholds=0.1)\n",
    "acc = tf.keras.metrics.BinaryAccuracy(name=\"binary_acc\", threshold=0.1)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[acc, recall])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.save('my_sequential_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 269s 5s/step - loss: 0.1762 - binary_acc: 0.8574 - recall: 0.7479 - val_loss: 0.1602 - val_binary_acc: 0.8027 - val_recall: 0.8575\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 270s 5s/step - loss: 0.1472 - binary_acc: 0.8842 - recall: 0.8030 - val_loss: 0.1374 - val_binary_acc: 0.8693 - val_recall: 0.8373\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 286s 5s/step - loss: 0.1352 - binary_acc: 0.8979 - recall: 0.8314 - val_loss: 0.1426 - val_binary_acc: 0.8513 - val_recall: 0.8391\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 272s 5s/step - loss: 0.1280 - binary_acc: 0.8979 - recall: 0.8443 - val_loss: 0.1329 - val_binary_acc: 0.8958 - val_recall: 0.8144\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 276s 5s/step - loss: 0.1197 - binary_acc: 0.9049 - recall: 0.8589 - val_loss: 0.1239 - val_binary_acc: 0.9003 - val_recall: 0.8373\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 281s 5s/step - loss: 0.1196 - binary_acc: 0.9061 - recall: 0.8672 - val_loss: 0.1345 - val_binary_acc: 0.9185 - val_recall: 0.7907\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 275s 5s/step - loss: 0.1148 - binary_acc: 0.9112 - recall: 0.8635 - val_loss: 0.1285 - val_binary_acc: 0.8910 - val_recall: 0.8522\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 276s 5s/step - loss: 0.1092 - binary_acc: 0.9116 - recall: 0.8753 - val_loss: 0.1407 - val_binary_acc: 0.9155 - val_recall: 0.7880\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 269s 4s/step - loss: 0.1086 - binary_acc: 0.9152 - recall: 0.8744 - val_loss: 0.1282 - val_binary_acc: 0.9220 - val_recall: 0.8021\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 270s 5s/step - loss: 0.1071 - binary_acc: 0.9117 - recall: 0.8836 - val_loss: 0.1324 - val_binary_acc: 0.8940 - val_recall: 0.8285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importations nécessaires\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lancement de l'entraînement du modèle.\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,\n",
    "   \n",
    "    verbose=1  \n",
    ")\n",
    "\n",
    "model.save('my_model_ml.h5')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 79s 4s/step - loss: 0.1324 - binary_acc: 0.8940 - recall: 0.8285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1324252486228943, 0.8940476179122925, 0.8284960389137268]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5eef9c6f679bbe21775da1f8f0cc05ebccc8a6f9c6f0cd7c626f51c4d5643a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
